{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torchvision import transforms\n",
    "\n",
    "from CRUMB import CRUMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 80\n",
    "imsize = 150 # this value is fixed\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "# import dataset:\n",
    "\n",
    "# data augmentation\n",
    "\n",
    "crop = transforms.CenterCrop(imsize)\n",
    "rotate = transforms.RandomRotation([-180, 180])\n",
    "totensor = transforms.ToTensor()\n",
    "normalise = transforms.Normalize((0.0029,), (0.0341,)) # CRUMB mean and stdev\n",
    "\n",
    "transforms = transforms.Compose([\n",
    "    crop,\n",
    "    rotate,\n",
    "    totensor,\n",
    "    normalise\n",
    "])\n",
    "\n",
    "# load training and test set\n",
    "# this will download CRUMB to a directory called \"crumb\"\n",
    "test_data = CRUMB('crumb', download=True, train=False, transform=transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "train_data = CRUMB('crumb', download=True, train=True, transform=transforms)\n",
    "train_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./CombinedCat/PNG/Scaled_Final/251.618_+038.521.png'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to retrieve a filename for image 0:\n",
    "\n",
    "test_data.filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, -1, -1, -1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to retrieve a complete label for image 0\n",
    "# this particular source is only found in MiraBest\n",
    "\n",
    "test_data.complete_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   2,   4,   7,   8,   9,  10,  11,  12,  13,  14,  15,  18,\n",
       "         21,  22,  24,  25,  28,  30,  31,  32,  35,  36,  38,  39,  41,\n",
       "         42,  43,  46,  47,  48,  50,  53,  56,  58,  59,  60,  63,  65,\n",
       "         67,  68,  70,  72,  75,  83,  84,  85,  87,  89,  93,  95,  96,\n",
       "        102, 104, 107, 110, 111, 112, 115, 116, 117, 118, 121, 123, 124,\n",
       "        125, 128, 131, 137, 140, 144, 146, 149, 152, 154, 158, 161, 162,\n",
       "        163, 166, 167, 168, 169, 170, 171, 173, 174, 175, 176, 177, 178,\n",
       "        179, 181, 182, 183, 184, 185, 186, 187, 188, 191, 193, 194, 195,\n",
       "        197, 199, 202, 203, 204, 206, 207, 208, 209, 210, 211, 212, 213,\n",
       "        214, 215, 216, 217, 219, 223, 224, 225, 228, 230, 231, 232, 233,\n",
       "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "        247, 248, 249, 250, 252, 260, 261]),)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find all the test set images which are in MiraBest\n",
    "np.where(np.transpose(test_data.complete_labels)[0] != -1)\n",
    "\n",
    "# you can find sources in FRDEEP using index [1], sources in AT17 using index [2], and sources in MB Hybrid using index [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.,    2.,    5., ..., 1838., 1839., 1840.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find all the training set sources which are only present in one dataset:\n",
    "\n",
    "single_set_sources = []\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "\n",
    "    if np.size(np.where(train_data.complete_labels[i] != -1)) == 1:\n",
    "        \n",
    "        single_set_sources = np.append(single_set_sources, i)\n",
    "        \n",
    "single_set_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
